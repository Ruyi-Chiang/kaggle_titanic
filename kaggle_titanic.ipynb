{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "file_name = \"train.csv\"\n",
    "train = pd.read_csv(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the dataset\n",
    "print train.shape\n",
    "train.head(5)\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values in the dataset\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explor Name\n",
    "\n",
    "def title_checker (name):\n",
    "    title_list = ['Mr.', 'Mrs.', 'Miss.', 'Master.', 'Dr.', 'Rev.']\n",
    "    split_name = name.split(' ')\n",
    "    for word in split_name:\n",
    "        if word in title_list:\n",
    "            index = title_list.index(word)\n",
    "            return title_list[index]\n",
    "       \n",
    "        \n",
    "train['Title'] = train['Name'].apply(title_checker)\n",
    "train.head()\n",
    "train['Title'].isnull().sum()\n",
    "\n",
    "#title_checker('Braund, Mr. Owen Harris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of age: 29.6991176471\n",
      "Mode of age: 24.0\n",
      "Std of age: 14.5264973323\n",
      "count    714.000000\n",
      "mean      29.699118\n",
      "std       14.526497\n",
      "min        0.420000\n",
      "25%       20.125000\n",
      "50%       28.000000\n",
      "75%       38.000000\n",
      "max       80.000000\n",
      "Name: Age, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33.57804823458039"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill the missing values in \"Age\" column with the mean\n",
    "\n",
    "print 'Mean of age:', train['Age'].mean()\n",
    "print 'Mode of age:', train['Age'].mode()[0]\n",
    "print 'Std of age:', train['Age'].std()\n",
    "sigma = train['Age'].std()\n",
    "mu = train['Age'].mean()\n",
    "\n",
    "\n",
    "\n",
    "print train['Age'].describe()\n",
    "\n",
    "# Randomly generate age with standard diviation \n",
    "import random\n",
    "nums = [random.gauss(mu, sigma) for _ in range(10)]\n",
    "random.gauss(mu, sigma) \n",
    "#abs(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "Title            0\n",
       "Family_size      0\n",
       "Cabin_cat        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Enginerring\n",
    "def cabin_categorizer (cabin):\n",
    "    cabin = str(cabin)\n",
    "    return cabin[0]\n",
    "\n",
    "def impute_cabin_with_class(pclass):\n",
    "    if pclass == 1:\n",
    "        return 'C'\n",
    "    elif pclass == 2:\n",
    "        return 'E'\n",
    "    elif pclass == 3:\n",
    "        return 'F'\n",
    "           \n",
    "def featuring_process(df):\n",
    "    # add family size column\n",
    "    df['Family_size'] = 1 + df['Parch'] + df['SibSp']\n",
    "    \n",
    "    # add cabin_cat by Cabin number\n",
    "    df['Cabin_cat'] = df['Cabin'].apply(cabin_categorizer)\n",
    "    missing_cabin_index = df[df['Cabin_cat'] == 'n'].index\n",
    "    for index in missing_cabin_index:\n",
    "        pclass = df.loc[index, 'Pclass']\n",
    "        df.loc[index, 'Cabin_cat'] = impute_cabin_with_class(pclass)\n",
    "        \n",
    "    # add Title by Name\n",
    "    df['Title'] = df['Name'].apply(title_checker)\n",
    "    df['Title'].fillna('no_title', inplace = True)\n",
    "\n",
    "featuring_process(train)\n",
    "\n",
    "train.isnull().sum()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert feature_list into numeric\n",
    "\n",
    "def assign_into_object(df, feature_list):\n",
    "    type_list = df.dtypes\n",
    "    for col in feature_list:\n",
    "        if type_list[col] == 'object':\n",
    "            unique_values, result_dict = transfor_to_numeric(df, col)\n",
    "            assign_numeric_values(df, col, unique_values, result_dict)\n",
    "    return df\n",
    "\n",
    "def transfor_to_numeric (df, col_name):\n",
    "    values = df[col_name]\n",
    "    unique_values = set(values)\n",
    "    unique_values = list(unique_values)\n",
    "    len_of_values = len(unique_values)\n",
    "    result_dict = dict( zip(unique_values, range(len_of_values)))\n",
    "    return unique_values, result_dict\n",
    "\n",
    "def assign_numeric_values(df, col_name, unique_values, result_dict):\n",
    "    for value in unique_values:\n",
    "        df[col_name][df[col_name] == value ] = result_dict[value]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruyi/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714\n",
      "(571, 6)\n",
      "(143, 6)\n",
      "(571,)\n",
      "(143,)\n"
     ]
    }
   ],
   "source": [
    "# Fill the missing ages with randomly assigned values\n",
    "#train['Age'].fillna(random.gauss(mu, sigma), inplace = True)\n",
    "\n",
    "# Exclude all missing ages\n",
    "#train.dropna(inplace = True, subset = ['Age'])\n",
    "\n",
    "\n",
    "# Method3: Build a prediction model for missing ages\n",
    "def missing_age_predictor(df):\n",
    "    featuring_process(df)\n",
    "    age_feature_list = ['Fare', 'SibSp','Pclass', 'Cabin_cat','Parch']\n",
    "    assign_into_object(df, age_feature_list)\n",
    "    \n",
    "    age_df = df[['Age','Fare', 'SibSp','Pclass', 'Cabin_cat','Parch']]\n",
    "    knownAge = df.loc[(df.Age.notnull())]\n",
    "    unknownAge = df.loc[(df.Age.isnull())]\n",
    "    \n",
    "    age_target =knownAge['Age'].values\n",
    "    age_features = knownAge[age_feature_list].values\n",
    "\n",
    "    from sklearn import linear_model\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(age_features, age_target)\n",
    "    predictAges = regr.predict(unknownAge[age_feature_list].values)\n",
    "    df.loc[(df.Age.isnull()), 'Age'] = predictAges\n",
    "    \n",
    "    return df\n",
    "\n",
    "age_feature_list = ['Fare', 'SibSp','Pclass', 'Cabin_cat','Parch', 'Title']\n",
    "assign_into_object(train, age_feature_list)\n",
    "\n",
    "age_df = train[['Age','Fare', 'SibSp','Pclass', 'Cabin_cat','Parch', 'Title']]\n",
    "knownAge = train.loc[(train.Age.notnull())]\n",
    "unknownAge = train.loc[(train.Age.isnull())]\n",
    "print len(knownAge)\n",
    "\n",
    "age_label = knownAge['Age'].values\n",
    "age_features = knownAge[age_feature_list].values\n",
    "\n",
    "\n",
    "# Split to train and test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_features, test_features, train_labels,test_labels = train_test_split(\n",
    "age_features, age_label, test_size = 0.2, random_state = 0 )\n",
    "\n",
    "print train_features.shape\n",
    "print test_features.shape\n",
    "print train_labels.shape\n",
    "print test_labels.shape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.263137089874\n"
     ]
    }
   ],
   "source": [
    "# Age prediction - SVR\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "svr_lin = SVR(kernel='linear')\n",
    "svr_lin.fit(train_features, train_labels)\n",
    "pred = svr_lin.predict(test_features)\n",
    "\n",
    "from sklearn.metrics import explained_variance_score\n",
    "print explained_variance_score(test_labels, pred)\n",
    "\n",
    "\n",
    "first_score = 0.256824329357\n",
    "second_score = 0.263137089874 #with title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction (143,)\n",
      "test_labels: (143,)\n",
      "0.266714714381\n"
     ]
    }
   ],
   "source": [
    "# Age prediction - Linear_model.Lasso\n",
    "\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.Lasso(alpha = 0.1)\n",
    "reg.fit(train_features, train_labels)\n",
    "pred = reg.predict(test_features)\n",
    "print 'prediction', pred.shape\n",
    "print 'test_labels:', test_labels.shape\n",
    "#reg.score(test_features, test_labels)\n",
    "\n",
    "from sklearn.metrics import explained_variance_score\n",
    "print explained_variance_score(test_labels, pred)\n",
    "\n",
    "first_score = 0.259438390473"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train = missing_age_predictor(train)\n",
    "print train.isnull().sum()\n",
    "train.shape\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Cabin  Pclass\n",
      "1   C85       1\n",
      "3  C123       1\n",
      "6   E46       1\n",
      "(204, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruyi/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Exploring Cabin data\n",
    "\n",
    "cabin_df = train[['Cabin', 'Pclass']]\n",
    "cabin_df.dropna(inplace = True)\n",
    "print cabin_df.head(3)\n",
    "print cabin_df.shape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "Family_size      0\n",
       "Cabin_cat        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuring_process(train)\n",
    "print train.shape\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', 'D', 'E', 'F', 'G', 'T'}"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train['Cabin_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['A', '1', '4', 'F'])\n",
      "4\n",
      "[0, 1, 2]\n",
      "[('A', 0), ('1', 1), ('4', 2), ('F', 3)]\n",
      "{'A': 0, '1': 1, '4': 2, 'F': 3}\n",
      "['PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch'\n",
      " 'Ticket' 'Fare' 'Cabin' 'Embarked' 'Family_size' 'Cabin_cat']\n",
      "zip: ['male', 'female'] {'male': 0, 'female': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruyi/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family_size</th>\n",
       "      <th>Cabin_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris   0  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...   1  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina   1  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)   1  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry   0  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked  Family_size Cabin_cat  \n",
       "0         A/5 21171   7.2500   NaN        S            2         F  \n",
       "1          PC 17599  71.2833   C85        C            2         C  \n",
       "2  STON/O2. 3101282   7.9250   NaN        S            1         F  \n",
       "3            113803  53.1000  C123        S            2         C  \n",
       "4            373450   8.0500   NaN        S            1         F  "
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n",
    "y2 = [\"A\",\"1\",\"4\",\"F\",\"A\",\"1\",\"4\",\"F\"]\n",
    "S = set(y2)\n",
    "print S\n",
    "print len(S)\n",
    "print range(3)\n",
    "print zip(S, range(len(S)))\n",
    "D = dict( zip(S, range(len(S))) )\n",
    "print D\n",
    "\n",
    "print train.columns.values\n",
    "\n",
    "\n",
    "\n",
    "unique_values, result_dict = transfor_to_numeric(train, \"Sex\")\n",
    "print 'zip:', unique_values, result_dict\n",
    "\n",
    "\n",
    "    \n",
    "assign_numeric_values (train, \"Sex\", unique_values, result_dict)\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruyi/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "Family_size      0\n",
       "Cabin_cat        0\n",
       "Title            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "feature_list = ['Sex', 'Age', 'Family_size', 'Cabin_cat', 'Title']\n",
    "train['Age'].fillna(random.gauss(mu, sigma), inplace = True)\n",
    "\n",
    "assign_into_object(train, feature_list)\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "# exclude datapoint without age number\n",
    "\n",
    "#train[\"Age\"][train[\"Age\"].isnull()] = 9999\n",
    "#print set(train[\"Age\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare for estimator testing\n",
    "# Whole dataset\n",
    "labels = train['Survived'].values\n",
    "features = train[feature_list].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Split to train and test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features, test_features, train_labels,test_labels = train_test_split(\n",
    "features, labels, test_size = 0.15, random_state = 0 )\n",
    "\n",
    "\n",
    "print \"Train features:\", train_features.shape\n",
    "print \"Train labels:\", train_labels.shape\n",
    "print \"Test features:\", test_features.shape\n",
    "print \"Test labels:\",test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 1: 0.800\n",
      "Score for fold 2: 0.820\n",
      "Score for fold 3: 0.775\n",
      "Score for fold 4: 0.809\n",
      "Score for fold 5: 0.764\n",
      "Score for fold 6: 0.764\n",
      "Score for fold 7: 0.764\n",
      "Score for fold 8: 0.753\n",
      "Score for fold 9: 0.865\n",
      "Score for fold 10: 0.775\n"
     ]
    }
   ],
   "source": [
    "# Use KFold to split train/test data\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Load the data:\n",
    "#iris = load_iris()\n",
    "#X, y = iris.data, iris.target\n",
    " \n",
    "# Split in 5 folds:\n",
    "#n = len(X)\n",
    "#kf = KFold(n_splits=5)\n",
    "#fold = 0\n",
    "#for train_idx, test_idx in kf.split(X):\n",
    "#    fold += 1\n",
    "#    X_train, X_test = X[train_idx], X[test_idx]\n",
    "#    y_train, y_test = y[train_idx], y[test_idx]\n",
    "#    clf = LogisticRegression().fit(X_train, y_train)\n",
    "#    score = clf.score(X_test, y_test)\n",
    "#    print(\"Score for fold %d: %.3f\" % (fold, score))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split in 5 folds\n",
    "n = len(train)\n",
    "kf = KFold(n_splits=10)\n",
    "fold = 0\n",
    "for train_idx, test_idx in kf.split(features):\n",
    "    fold += 1\n",
    "    X_train, X_test = features[train_idx], features[test_idx]\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "    clf = LogisticRegression().fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(\"Score for fold %d: %.3f\" % (fold, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf name: LinearSVC\n",
      "Cross-validated scores: 0.751946122172\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC\n",
    "import time\n",
    "from sklearn import svm\n",
    "\n",
    "print 'clf name: LinearSVC'\n",
    "clf = svm.LinearSVC()\n",
    "'''\n",
    "t0 = time.time()\n",
    "clf.fit(train_features, train_labels)\n",
    "print \"training time:\", round(time.time()-t0, 3), \"s\"\n",
    "\n",
    "t0 = time.time()\n",
    "pred = clf.predict(test_features)\n",
    "print \"predicting time:\", round(time.time()-t0, 3), \"s\"\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(pred, test_labels)\n",
    "print 'Accuracy score:', accuracy\n",
    "'''\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "scores = cross_val_score(clf, features, labels, cv=5)\n",
    "print 'Cross-validated scores:', scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: 0.801347229418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruyi/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# naive_bayes_clf\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "'''   \n",
    "print 'clf name: Naive Bayes'\n",
    "t0 = time.time()\n",
    "clf.fit(train_features, train_labels)\n",
    "print \"training time:\", round(time.time()-t0, 3), \"s\"\n",
    "\n",
    "t0 = time.time()\n",
    "pred = clf.predict(test_features)\n",
    "print \"predicting time:\", round(time.time()-t0, 3), \"s\"\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(pred, test_labels)\n",
    "print 'accuracy score:', accuracy\n",
    "\n",
    "print 'GaussianNB priors:', clf.class_prior_\n",
    "'''\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "scores = cross_val_score(clf, features, labels, cv=5)\n",
    "print 'Cross-validated scores:', scores.mean()\n",
    "\n",
    "clf.fit(features, labels)\n",
    "\n",
    "previous_score = 0.791285015499\n",
    "seconde_score = 0.801347229418  #feature_list = ['Sex', 'Age', 'Family_size', 'Cabin_cat', 'Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: 0.760947511284\n"
     ]
    }
   ],
   "source": [
    "### KNeighbors clf\n",
    "def Kneightbors_clf(features_train,labels_train, \\\n",
    "                    features_test,labels_test):\n",
    "\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    clf = KNeighborsClassifier(n_neighbors = 2)\n",
    "    \n",
    "    print 'clf name: KNeighbors'\n",
    "    t0 = time.time()\n",
    "    clf.fit(features_train, labels_train)\n",
    "    print \"training time:\", round(time.time()-t0, 3), \"s\"\n",
    "\n",
    "    t0 = time.time()\n",
    "    pred = clf.predict(features_test)\n",
    "    print \"predicting time:\", round(time.time()-t0, 3), \"s\"\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score\n",
    "    accuracy = accuracy_score(pred, labels_test)\n",
    "    print 'accuracy score:', accuracy\n",
    "\n",
    "#Kneightbors_clf(train_features, train_labels, \\\n",
    "#              test_features, test_labels)    \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors = 2)\n",
    "\n",
    "scores = cross_val_score(clf, features, labels, cv=5)\n",
    "print 'Cross-validated scores:', scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: 0.789031405564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### SVC clf\n",
    "\n",
    "def SVC_clf(features_train,labels_train, \\\n",
    "                    features_test,labels_test):\n",
    "\n",
    "    from sklearn import svm\n",
    "    clf = svm.SVC(C=1.0, kernel='rbf')\n",
    "    \n",
    "    print 'clf name: SVC'\n",
    "    t0 = time.time()\n",
    "    clf.fit(features_train, labels_train)\n",
    "    print \"training time:\", round(time.time()-t0, 3), \"s\"\n",
    "\n",
    "    t0 = time.time()\n",
    "    pred = clf.predict(features_test)\n",
    "    print \"predicting time:\", round(time.time()-t0, 3), \"s\"\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    accuracy = accuracy_score(pred, labels_test)\n",
    "    print 'accuracy score:', accuracy\n",
    "\n",
    "#SVC_clf(train_features, train_labels, \\\n",
    "#              test_features, test_labels)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(C=1.0, kernel='rbf')\n",
    "\n",
    "scores = cross_val_score(clf, features, labels, cv=5)\n",
    "print 'Cross-validated scores:', scores.mean()\n",
    "\n",
    "clf.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator found by grid search:\n",
      "Pipeline(steps=[('Scale_Features', MinMaxScaler(copy=True, feature_range=(0, 1))), ('SKB', SelectKBest(k=1, score_func=<function f_classif at 0x1159b26e0>)), ('Classifier', SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best Params found by grid search:\n",
      "{'Classifier__kernel': 'linear', 'Classifier__C': 1, 'SKB__k': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.grid_search import GridSearchCV #sklearn version 0.15\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "skb = SelectKBest()\n",
    "clf = svm.SVC()\n",
    "pipe = Pipeline([('Scale_Features',scaler),('SKB', skb),('Classifier',clf)])\n",
    "\n",
    "#print sorted(pipe.get_params().keys())\n",
    "\n",
    "params = {'SKB__k':range(1,len(feature_list)),'Classifier__kernel':['linear', 'rbf'], 'Classifier__C':[1, 10, 20]}\n",
    "my_clf = GridSearchCV(pipe, param_grid=params, scoring='f1_weighted')\n",
    "my_clf.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "pred = my_clf.predict(test_features)\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print my_clf.best_estimator_\n",
    "print('Best Params found by grid search:')\n",
    "print my_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tune parameters of Naives Bayes with GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, \\\n",
    "                            recall_score, f1_score\n",
    "\n",
    "skb = SelectKBest()\n",
    "clf = GaussianNB()\n",
    "pipe = Pipeline([('SKB', skb),('Classifier',clf)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruyi/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "Family_size      0\n",
      "Cabin_cat        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Test dataset\n",
    "test = pd.read_csv('test.csv')\n",
    "print test.head()\n",
    "featuring_process(test)\n",
    "assign_into_object(test, feature_list)\n",
    "\n",
    "\n",
    "unknownAges_test = test.loc[(test.Age.isnull())]\n",
    "predictAges_test = regr.predict(unknownAges_test[age_feature_list].values)\n",
    "test.loc[(test.Age.isnull()), 'Age'] = predictAges_test    \n",
    "\n",
    "\n",
    "print test.isnull().sum()\n",
    "\n",
    "    \n",
    "'''\n",
    "assign_into_object(test, feature_list)\n",
    "\n",
    "print feature_list\n",
    "'''\n",
    "test_features = test[feature_list].values\n",
    "\n",
    "pred = clf.predict(test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Survived\n",
      "892          0\n",
      "893          1\n",
      "894          0\n",
      "895          0\n",
      "896          1\n",
      "897          0\n",
      "898          1\n",
      "899          0\n",
      "900          1\n",
      "901          0\n",
      "902          0\n",
      "903          0\n",
      "904          1\n",
      "905          0\n",
      "906          1\n",
      "907          1\n",
      "908          0\n",
      "909          0\n",
      "910          1\n",
      "911          1\n",
      "912          0\n",
      "913          0\n",
      "914          1\n",
      "915          0\n",
      "916          1\n",
      "917          0\n",
      "918          1\n",
      "919          0\n",
      "920          1\n",
      "921          0\n",
      "...        ...\n",
      "1280         0\n",
      "1281         0\n",
      "1282         0\n",
      "1283         1\n",
      "1284         0\n",
      "1285         0\n",
      "1286         0\n",
      "1287         1\n",
      "1288         0\n",
      "1289         1\n",
      "1290         0\n",
      "1291         0\n",
      "1292         1\n",
      "1293         0\n",
      "1294         1\n",
      "1295         0\n",
      "1296         0\n",
      "1297         0\n",
      "1298         0\n",
      "1299         0\n",
      "1300         1\n",
      "1301         1\n",
      "1302         1\n",
      "1303         1\n",
      "1304         1\n",
      "1305         0\n",
      "1306         1\n",
      "1307         0\n",
      "1308         0\n",
      "1309         0\n",
      "\n",
      "[418 rows x 1 columns]\n",
      "(418, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a data frame with two columns: PassengerId & Survived. Survived contains your predictions\n",
    "PassengerId =np.array(test[\"PassengerId\"]).astype(int)\n",
    "my_solution = pd.DataFrame(pred, PassengerId, columns = [\"Survived\"])\n",
    "print(my_solution)\n",
    "\n",
    "# Check that your data frame has 418 entries\n",
    "print(my_solution.shape)\n",
    "\n",
    "# Write your solution to a csv file with the name my_solution.csv\n",
    "my_solution.to_csv(\"my_solution_8.csv\", index_label = [\"PassengerId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s2 = pd.read_csv(\"my_solution_2.csv\")\n",
    "s3 = pd.read_csv(\"my_solution_3.csv\")\n",
    "s4 = pd.read_csv(\"my_solution_4.csv\")\n",
    "s5 = pd.read_csv(\"my_solution_5.csv\")\n",
    "s6 = pd.read_csv(\"my_solution_6.csv\")\n",
    "s7 = pd.read_csv(\"my_solution_7.csv\")\n",
    "s8 = pd.read_csv(\"my_solution_8.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s7.equals(s8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n",
      "152\n",
      "184\n",
      "139\n",
      "152\n",
      "149\n",
      "151\n"
     ]
    }
   ],
   "source": [
    "def count_survival(df):\n",
    "    print df['Survived'].sum()\n",
    "\n",
    "count_survival(s2)\n",
    "count_survival(s3)    \n",
    "count_survival(s4)\n",
    "count_survival(s5)\n",
    "count_survival(s6)\n",
    "count_survival(s7)\n",
    "count_survival(s8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
