{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "file_name = \"train.csv\"\n",
    "train = pd.read_csv(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the dataset\n",
    "print train.shape\n",
    "train.head(5)\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values in the dataset\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of age: 29.6991176471\n",
      "Mode of age: 24.0\n"
     ]
    }
   ],
   "source": [
    "# fill the missing values in \"Age\" column with the mean\n",
    "\n",
    "print 'Mean of age:', train['Age'].mean()\n",
    "print 'Mode of age:', train['Age'].mode()[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Age'].fillna(train['Age'].mode()[0], inplace = True)\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Cabin  Pclass\n",
      "1   C85       1\n",
      "3  C123       1\n",
      "6   E46       1\n",
      "(204, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruyi/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Exploring Cabin data\n",
    "\n",
    "cabin_df = train[['Cabin', 'Pclass']]\n",
    "cabin_df.dropna(inplace = True)\n",
    "print cabin_df.head(3)\n",
    "print cabin_df.shape\n",
    "\n",
    "\n",
    "def cabin_categorizer (cabin):\n",
    "    cabin = str(cabin)\n",
    "    return cabin[0]\n",
    "\n",
    "def impute_cabin_with_class(pclass):\n",
    "    if pclass == 1:\n",
    "        return 'C'\n",
    "    elif pclass == 2:\n",
    "        return 'E'\n",
    "    elif pclass == 3:\n",
    "        return 'F'\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature Enginerring\n",
    "\n",
    "def featuring_process(df):\n",
    "    # add family size column\n",
    "    df['Family_size'] = 1 + df['Parch'] + df['SibSp']\n",
    "    \n",
    "    # add cabin_cat by Cabin number\n",
    "    df['Cabin_cat'] = df['Cabin'].apply(cabin_categorizer)\n",
    "    missing_cabin_index = df[df['Cabin_cat'] == 'n'].index\n",
    "    for index in missing_cabin_index:\n",
    "        pclass = df.loc[index, 'Pclass']\n",
    "        df.loc[index, 'Cabin_cat'] = impute_cabin_with_class(pclass)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "Family_size      0\n",
       "Cabin_cat        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuring_process(train)\n",
    "print train.shape\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', 'D', 'E', 'F', 'G', 'T'}"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train['Cabin_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['A', '1', '4', 'F'])\n",
      "4\n",
      "[0, 1, 2]\n",
      "[('A', 0), ('1', 1), ('4', 2), ('F', 3)]\n",
      "{'A': 0, '1': 1, '4': 2, 'F': 3}\n",
      "['PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch'\n",
      " 'Ticket' 'Fare' 'Cabin' 'Embarked' 'Family_size' 'Cabin_cat']\n",
      "zip: ['male', 'female'] {'male': 0, 'female': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruyi/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family_size</th>\n",
       "      <th>Cabin_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris   0  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...   1  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina   1  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)   1  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry   0  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked  Family_size Cabin_cat  \n",
       "0         A/5 21171   7.2500   NaN        S            2         F  \n",
       "1          PC 17599  71.2833   C85        C            2         C  \n",
       "2  STON/O2. 3101282   7.9250   NaN        S            1         F  \n",
       "3            113803  53.1000  C123        S            2         C  \n",
       "4            373450   8.0500   NaN        S            1         F  "
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n",
    "y2 = [\"A\",\"1\",\"4\",\"F\",\"A\",\"1\",\"4\",\"F\"]\n",
    "S = set(y2)\n",
    "print S\n",
    "print len(S)\n",
    "print range(3)\n",
    "print zip(S, range(len(S)))\n",
    "D = dict( zip(S, range(len(S))) )\n",
    "print D\n",
    "\n",
    "print train.columns.values\n",
    "\n",
    "def transfor_to_numeric (df, col_name):\n",
    "    values = df[col_name]\n",
    "    unique_values = set(values)\n",
    "    unique_values = list(unique_values)\n",
    "    len_of_values = len(unique_values)\n",
    "    result_dict = dict( zip(unique_values, range(len_of_values)))\n",
    "    return unique_values, result_dict\n",
    "\n",
    "unique_values, result_dict = transfor_to_numeric(train, \"Sex\")\n",
    "print 'zip:', unique_values, result_dict\n",
    "\n",
    "def assign_numeric_values(df, col_name, unique_values, result_dict):\n",
    "    for value in unique_values:\n",
    "        df[col_name][df[col_name] == value ] = result_dict[value]\n",
    "    return df\n",
    "    \n",
    "assign_numeric_values (train, \"Sex\", unique_values, result_dict)\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruyi/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name Sex   Age  SibSp  Parch  \\\n",
      "0                            Braund, Mr. Owen Harris   0  22.0      1      0   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...   1  38.0      1      0   \n",
      "2                             Heikkinen, Miss. Laina   1  26.0      0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)   1  35.0      1      0   \n",
      "4                           Allen, Mr. William Henry   0  35.0      0      0   \n",
      "\n",
      "             Ticket     Fare Cabin Embarked  Family_size Cabin_cat  \n",
      "0         A/5 21171   7.2500   NaN        S            2         6  \n",
      "1          PC 17599  71.2833   C85        C            2         1  \n",
      "2  STON/O2. 3101282   7.9250   NaN        S            1         6  \n",
      "3            113803  53.1000  C123        S            2         1  \n",
      "4            373450   8.0500   NaN        S            1         6  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_list = ['Sex', 'Age', 'Family_size', 'Cabin_cat']\n",
    "\n",
    "def assign_into_object(df, feature_list):\n",
    "    type_list = df.dtypes\n",
    "    for col in feature_list:\n",
    "        if type_list[col] == 'object':\n",
    "            unique_values, result_dict = transfor_to_numeric(df, col)\n",
    "            assign_numeric_values(df, col, unique_values, result_dict)\n",
    "    return df\n",
    "\n",
    "assign_into_object(train, feature_list)\n",
    "print train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "# exclude datapoint without age number\n",
    "print set(train[\"Cabin_cat\"])\n",
    "#train[\"Age\"][train[\"Age\"].isnull()] = 9999\n",
    "#print set(train[\"Age\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: (712, 4)\n",
      "Train labels: (712,)\n",
      "Test features: (179, 4)\n",
      "Test labels: (179,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare for estimator testing\n",
    "# Whole dataset\n",
    "labels = train['Survived'].values\n",
    "features = train[feature_list].values\n",
    "\n",
    "\n",
    "# Split to train and test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features, test_features, train_labels,test_labels = train_test_split(\n",
    "features, labels, test_size = 0.2, random_state = 0 )\n",
    "\n",
    "\n",
    "print \"Train features:\", train_features.shape\n",
    "print \"Train labels:\", train_labels.shape\n",
    "print \"Test features:\", test_features.shape\n",
    "print \"Test labels:\",test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 1: 1.000\n",
      "Score for fold 2: 0.933\n",
      "Score for fold 3: 0.433\n",
      "Score for fold 4: 0.967\n",
      "Score for fold 5: 0.433\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 179 is out of bounds for axis 0 with size 150",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-278-616a214a607b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mfold\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 179 is out of bounds for axis 0 with size 150"
     ]
    }
   ],
   "source": [
    "# Use KFold to split train/test data\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    " \n",
    "# Load the data:\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    " \n",
    "# Split in 5 folds:\n",
    "n = len(X)\n",
    "kf = KFold(n_splits=5)\n",
    "fold = 0\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    fold += 1\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    clf = LogisticRegression().fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(\"Score for fold %d: %.3f\" % (fold, score))\n",
    "    \n",
    "# Split in 5 folds\n",
    "n = len(train)\n",
    "kf = KFold(n_splits=5)\n",
    "fold = 0\n",
    "for train_idx, test_idx in kf.split(train):\n",
    "    fold += 1\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    clf = LogisticRegression().fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(\"Score for fold %d: %.3f\" % (fold, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf name: LinearSVC\n",
      "training time: 0.033 s\n",
      "predicting time: 0.0 s\n",
      "Accuracy score: 0.759776536313\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC\n",
    "import time\n",
    "from sklearn import svm\n",
    "\n",
    "print 'clf name: LinearSVC'\n",
    "clf = svm.LinearSVC()\n",
    "\n",
    "t0 = time.time()\n",
    "clf.fit(train_features, train_labels)\n",
    "print \"training time:\", round(time.time()-t0, 3), \"s\"\n",
    "\n",
    "t0 = time.time()\n",
    "pred = clf.predict(test_features)\n",
    "print \"predicting time:\", round(time.time()-t0, 3), \"s\"\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(pred, test_labels)\n",
    "print 'Accuracy score:', accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf name: Naive Bayes\n",
      "training time: 0.002 s\n",
      "predicting time: 0.001 s\n",
      "accuracy score: 0.776536312849\n",
      "GaussianNB priors: [ 0.61657303  0.38342697]\n"
     ]
    }
   ],
   "source": [
    "# naive_bayes_clf\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "    \n",
    "print 'clf name: Naive Bayes'\n",
    "t0 = time.time()\n",
    "clf.fit(train_features, train_labels)\n",
    "print \"training time:\", round(time.time()-t0, 3), \"s\"\n",
    "\n",
    "t0 = time.time()\n",
    "pred = clf.predict(test_features)\n",
    "print \"predicting time:\", round(time.time()-t0, 3), \"s\"\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(pred, test_labels)\n",
    "print 'accuracy score:', accuracy\n",
    "\n",
    "print 'GaussianNB priors:', clf.class_prior_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf name: KNeighbors\n",
      "training time: 0.002 s\n",
      "predicting time: 0.002 s\n",
      "accuracy score: 0.720670391061\n"
     ]
    }
   ],
   "source": [
    "### KNeighbors clf\n",
    "def Kneightbors_clf(features_train,labels_train, \\\n",
    "                    features_test,labels_test):\n",
    "\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    clf = KNeighborsClassifier(n_neighbors = 2)\n",
    "    \n",
    "    print 'clf name: KNeighbors'\n",
    "    t0 = time.time()\n",
    "    clf.fit(features_train, labels_train)\n",
    "    print \"training time:\", round(time.time()-t0, 3), \"s\"\n",
    "\n",
    "    t0 = time.time()\n",
    "    pred = clf.predict(features_test)\n",
    "    print \"predicting time:\", round(time.time()-t0, 3), \"s\"\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score\n",
    "    accuracy = accuracy_score(pred, labels_test)\n",
    "    print 'accuracy score:', accuracy\n",
    "\n",
    "Kneightbors_clf(train_features, train_labels, \\\n",
    "              test_features, test_labels)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf name: SVC\n",
      "training time: 0.016 s\n",
      "predicting time: 0.002 s\n",
      "accuracy score: 0.810055865922\n"
     ]
    }
   ],
   "source": [
    "### SVC clf\n",
    "\n",
    "def SVC_clf(features_train,labels_train, \\\n",
    "                    features_test,labels_test):\n",
    "\n",
    "    from sklearn import svm\n",
    "    clf = svm.SVC(C=1.0, kernel='rbf')\n",
    "    \n",
    "    print 'clf name: SVC'\n",
    "    t0 = time.time()\n",
    "    clf.fit(features_train, labels_train)\n",
    "    print \"training time:\", round(time.time()-t0, 3), \"s\"\n",
    "\n",
    "    t0 = time.time()\n",
    "    pred = clf.predict(features_test)\n",
    "    print \"predicting time:\", round(time.time()-t0, 3), \"s\"\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    accuracy = accuracy_score(pred, labels_test)\n",
    "    print 'accuracy score:', accuracy\n",
    "\n",
    "SVC_clf(train_features, train_labels, \\\n",
    "              test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator found by grid search:\n",
      "Pipeline(steps=[('Scale_Features', MinMaxScaler(copy=True, feature_range=(0, 1))), ('SKB', SelectKBest(k=1, score_func=<function f_classif at 0x1159b26e0>)), ('Classifier', SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best Params found by grid search:\n",
      "{'Classifier__kernel': 'linear', 'Classifier__C': 1, 'SKB__k': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.grid_search import GridSearchCV #sklearn version 0.15\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "skb = SelectKBest()\n",
    "clf = svm.SVC()\n",
    "pipe = Pipeline([('Scale_Features',scaler),('SKB', skb),('Classifier',clf)])\n",
    "\n",
    "#print sorted(pipe.get_params().keys())\n",
    "\n",
    "params = {'SKB__k':range(1,len(feature_list)),'Classifier__kernel':['linear', 'rbf'], 'Classifier__C':[1, 10, 20]}\n",
    "my_clf = GridSearchCV(pipe, param_grid=params, scoring='f1_weighted')\n",
    "my_clf.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "pred = my_clf.predict(test_features)\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print my_clf.best_estimator_\n",
    "print('Best Params found by grid search:')\n",
    "print my_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tune parameters of Naives Bayes with GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, \\\n",
    "                            recall_score, f1_score\n",
    "\n",
    "skb = SelectKBest()\n",
    "clf = GaussianNB()\n",
    "pipe = Pipeline([('SKB', skb),('Classifier',clf)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruyi/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sex', 'Age', 'Family_size', 'Cabin_cat']\n"
     ]
    }
   ],
   "source": [
    "# Test dataset\n",
    "test = pd.read_csv('test.csv')\n",
    "featuring_process(test)\n",
    "assign_into_object(test, feature_list)\n",
    "print feature_list\n",
    "\n",
    "\n",
    "test.isnull().sum()\n",
    "\n",
    "train_mode_age = 24\n",
    "test['Age'].fillna(train_mode_age, inplace = True)\n",
    "test.isnull().sum()\n",
    "\n",
    "\n",
    "test_features = test[feature_list].values\n",
    "\n",
    "pred = clf.predict(test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Survived\n",
      "892          0\n",
      "893          1\n",
      "894          0\n",
      "895          0\n",
      "896          1\n",
      "897          0\n",
      "898          1\n",
      "899          0\n",
      "900          1\n",
      "901          0\n",
      "902          0\n",
      "903          1\n",
      "904          1\n",
      "905          0\n",
      "906          1\n",
      "907          1\n",
      "908          0\n",
      "909          0\n",
      "910          1\n",
      "911          1\n",
      "912          1\n",
      "913          0\n",
      "914          1\n",
      "915          1\n",
      "916          1\n",
      "917          0\n",
      "918          1\n",
      "919          0\n",
      "920          1\n",
      "921          0\n",
      "...        ...\n",
      "1280         0\n",
      "1281         0\n",
      "1282         0\n",
      "1283         1\n",
      "1284         0\n",
      "1285         0\n",
      "1286         0\n",
      "1287         1\n",
      "1288         0\n",
      "1289         1\n",
      "1290         0\n",
      "1291         0\n",
      "1292         1\n",
      "1293         0\n",
      "1294         1\n",
      "1295         1\n",
      "1296         0\n",
      "1297         0\n",
      "1298         0\n",
      "1299         1\n",
      "1300         1\n",
      "1301         1\n",
      "1302         1\n",
      "1303         1\n",
      "1304         1\n",
      "1305         0\n",
      "1306         1\n",
      "1307         0\n",
      "1308         0\n",
      "1309         0\n",
      "\n",
      "[418 rows x 1 columns]\n",
      "(418, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a data frame with two columns: PassengerId & Survived. Survived contains your predictions\n",
    "PassengerId =np.array(test[\"PassengerId\"]).astype(int)\n",
    "my_solution = pd.DataFrame(pred, PassengerId, columns = [\"Survived\"])\n",
    "print(my_solution)\n",
    "\n",
    "# Check that your data frame has 418 entries\n",
    "print(my_solution.shape)\n",
    "\n",
    "# Write your solution to a csv file with the name my_solution.csv\n",
    "my_solution.to_csv(\"my_solution_4.csv\", index_label = [\"PassengerId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s2 = pd.read_csv(\"my_solution_2.csv\")\n",
    "s3 = pd.read_csv(\"my_solution_3.csv\")\n",
    "s4 = pd.read_csv(\"my_solution_4.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.equals(s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n",
      "152\n",
      "184\n"
     ]
    }
   ],
   "source": [
    "def count_survival(df):\n",
    "    print df['Survived'].sum()\n",
    "\n",
    "count_survival(s2)\n",
    "count_survival(s3)    \n",
    "count_survival(s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
