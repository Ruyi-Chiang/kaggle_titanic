{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "file_name = \"train.csv\"\n",
    "train = pd.read_csv(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the dataset\n",
    "print train.shape\n",
    "train.head(5)\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values in the dataset\n",
    "train.isnull().sum()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Classify Age_group by Age\n",
    "\n",
    "def age_grouping (age):\n",
    "    if age < 10:\n",
    "        return 'Below 10'\n",
    "    elif age >= 10 and age <= 15:\n",
    "        return '10-15'\n",
    "    elif age > 15 and age <= 20:\n",
    "        return '16-20'\n",
    "    elif age > 20 and age <= 30:\n",
    "        return '21-30'\n",
    "    elif age > 30 and age <= 40:\n",
    "        return '31-40'\n",
    "    elif age > 40 and age <= 50:\n",
    "        return '41-50'\n",
    "    elif age > 50 and age <= 60:\n",
    "        return '51-60'\n",
    "    elif age > 60:\n",
    "        return 'Above 60'\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Explor Name\n",
    "\n",
    "def title_checker (name):\n",
    "    title_list = ['Mr.', 'Mrs.', 'Miss.', 'Master.', 'Dr.', 'Rev.']\n",
    "    split_name = name.split(' ')\n",
    "    for word in split_name:\n",
    "        if word in title_list:\n",
    "            index = title_list.index(word)\n",
    "            return title_list[index]\n",
    "       \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of age: 29.6991176471\n",
      "Mode of age: 24.0\n",
      "Std of age: 14.5264973323\n",
      "count    714.000000\n",
      "mean      29.699118\n",
      "std       14.526497\n",
      "min        0.420000\n",
      "25%       20.125000\n",
      "50%       28.000000\n",
      "75%       38.000000\n",
      "max       80.000000\n",
      "Name: Age, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27.31255388052082"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill the missing values in \"Age\" column with the mean\n",
    "\n",
    "print 'Mean of age:', train['Age'].mean()\n",
    "print 'Mode of age:', train['Age'].mode()[0]\n",
    "print 'Std of age:', train['Age'].std()\n",
    "sigma = train['Age'].std()\n",
    "mu = train['Age'].mean()\n",
    "\n",
    "\n",
    "\n",
    "print train['Age'].describe()\n",
    "\n",
    "# Randomly generate age with standard diviation \n",
    "import random\n",
    "nums = [random.gauss(mu, sigma) for _ in range(10)]\n",
    "random.gauss(mu, sigma) \n",
    "#abs(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature Enginerring\n",
    "def cabin_categorizer (cabin):\n",
    "    cabin = str(cabin)\n",
    "    return cabin[0]\n",
    "\n",
    "def impute_cabin_with_class(pclass):\n",
    "    if pclass == 1:\n",
    "        return 'C'\n",
    "    elif pclass == 2:\n",
    "        return 'E'\n",
    "    elif pclass == 3:\n",
    "        return 'F'\n",
    "           \n",
    "def featuring_process(df):\n",
    "    # add family size column\n",
    "    df['Family_size'] = 1 + df['Parch'] + df['SibSp']\n",
    "    \n",
    "    # add cabin_cat by Cabin number\n",
    "    df['Cabin_cat'] = df['Cabin'].apply(cabin_categorizer)\n",
    "    missing_cabin_index = df[df['Cabin_cat'] == 'n'].index\n",
    "    for index in missing_cabin_index:\n",
    "        pclass = df.loc[index, 'Pclass']\n",
    "        df.loc[index, 'Cabin_cat'] = impute_cabin_with_class(pclass)\n",
    "        \n",
    "    # add Title by Name\n",
    "    df['Title'] = df['Name'].apply(title_checker)\n",
    "    df['Title'].fillna('no_title', inplace = True)\n",
    "    \n",
    "    # predict missing Age by ['Fare', 'SibSp','Pclass', 'Cabin_cat','Parch', 'Title']\n",
    "    #missing_age_predictor(df)\n",
    "    \n",
    "    # add Age_group by Age\n",
    "    df['Age_group'] = df['Age'].apply(age_grouping)\n",
    "    \n",
    "    return df\n",
    "   \n",
    "    \n",
    "train = featuring_process(train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert feature_list into numeric\n",
    "\n",
    "def assign_into_object(df, feature_list):\n",
    "    type_list = df.dtypes\n",
    "    for col in feature_list:\n",
    "        if type_list[col] == 'object':\n",
    "            unique_values, result_dict = transfor_to_numeric(df, col)\n",
    "            assign_numeric_values(df, col, unique_values, result_dict)\n",
    "    return df\n",
    "\n",
    "def transfor_to_numeric (df, col_name):\n",
    "    values = df[col_name]\n",
    "    unique_values = set(values)\n",
    "    unique_values = list(unique_values)\n",
    "    len_of_values = len(unique_values)\n",
    "    result_dict = dict( zip(unique_values, range(len_of_values)))\n",
    "    return unique_values, result_dict\n",
    "\n",
    "def assign_numeric_values(df, col_name, unique_values, result_dict):\n",
    "    for value in unique_values:\n",
    "        df[col_name][df[col_name] == value ] = result_dict[value]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill the missing ages with randomly assigned values\n",
    "#train['Age'].fillna(random.gauss(mu, sigma), inplace = True)\n",
    "\n",
    "# Exclude all missing ages\n",
    "#train.dropna(inplace = True, subset = ['Age'])\n",
    "\n",
    "\n",
    "# Method3: Build a prediction model for missing ages\n",
    "def missing_age_predictor(df):\n",
    "    age_feature_list = ['Fare', 'SibSp','Pclass', 'Cabin_cat', 'Parch', 'Title'] # around 26% accuracy\n",
    "    assign_into_object(df, age_feature_list)\n",
    "    \n",
    "    knownAge = df.loc[(df.Age.notnull())]\n",
    "    unknownAge = df.loc[(df.Age.isnull())]\n",
    "    \n",
    "    age_target =knownAge['Age'].values\n",
    "    age_features = knownAge[age_feature_list].values\n",
    "    unknown_age_features = unknownAge[age_feature_list].values\n",
    "    \n",
    "    from sklearn import linear_model\n",
    "    reg = linear_model.Lasso(alpha = 0.1)\n",
    "    reg.fit(age_features, age_target)\n",
    "    predict_age = reg.predict(unknown_age_features)\n",
    "    \n",
    "    df.loc[(df.Age.isnull()), 'Age'] = predict_age\n",
    "    \n",
    "#missing_age_predictor(train)\n",
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruyi/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714\n",
      "(571, 6)\n",
      "(143, 6)\n",
      "(571,)\n",
      "(143,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "age_feature_list = ['Fare', 'SibSp','Pclass', 'Cabin_cat', 'Parch', 'Title']\n",
    "process_feature_list = ['Fare', 'SibSp','Pclass', 'Cabin_cat','Parch', 'Title', 'Age_group', 'Age']\n",
    "assign_into_object(train, process_feature_list)\n",
    "\n",
    "knownAge = train.loc[(train.Age.notnull())]\n",
    "unknownAge = train.loc[(train.Age.isnull())]\n",
    "print len(knownAge)\n",
    "\n",
    "age_label = knownAge['Age'].values\n",
    "age_features = knownAge[age_feature_list].values\n",
    "\n",
    "\n",
    "# Split to train and test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_features, test_features, train_labels,test_labels = train_test_split(\n",
    "age_features, age_label, test_size = 0.2, random_state = 0 )\n",
    "\n",
    "print train_features.shape\n",
    "print test_features.shape\n",
    "print train_labels.shape\n",
    "print test_labels.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.264842983123\n"
     ]
    }
   ],
   "source": [
    "# Age prediction - SVR\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "svr_lin = SVR(kernel='linear')\n",
    "svr_lin.fit(train_features, train_labels)\n",
    "pred = svr_lin.predict(test_features)\n",
    "\n",
    "from sklearn.metrics import explained_variance_score\n",
    "print explained_variance_score(test_labels, pred)\n",
    "\n",
    "\n",
    "first_score = 0.256824329357\n",
    "second_score = 0.263137089874 #with title\n",
    "thrid_score = 0.672722482 # add Age_group - ['Fare', 'SibSp','Pclass', 'Cabin_cat','Parch', 'Title', 'Age_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction (143,)\n",
      "test_labels: (143,)\n",
      "0.266714714117\n"
     ]
    }
   ],
   "source": [
    "# Age prediction - Linear_model.Lasso\n",
    "\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.Lasso(alpha = 0.1)\n",
    "reg.fit(train_features, train_labels)\n",
    "pred = reg.predict(test_features)\n",
    "print 'prediction', pred.shape\n",
    "print 'test_labels:', test_labels.shape\n",
    "#reg.score(test_features, test_labels)\n",
    "\n",
    "from sklearn.metrics import explained_variance_score\n",
    "print explained_variance_score(test_labels, pred)\n",
    "\n",
    "first_score = 0.259438390473"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruyi/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714\n",
      "[1 5 1 5 5 7 0 1 2 0 7 3 5 2 7 0 5 5 5 2 1 0 5 3 5 4 1 6 1 3 2 5 1 0 3 3 0\n",
      " 1 6 1 4 1 1 0 2 1 5 6 0 1 3 3 1 5 3 1 1 5 1 0 1 1 1 1 3 5 3 1 1 1 3 6 1 7\n",
      " 4 1 5 5 1 1 5 5 1 1 5 6 2 1 3 3 1 4 1 1 0 1 5 5 7 2 1 6 5 3 6 1 1 1 3 5 3\n",
      " 1 1 1 3 3 3 1 0 5 6 7 1 7 6 7 3 1 6 5 1 3 0 0 6 1 4 0 0 1 7 3 6 1 5 0 0 0\n",
      " 6 5 5 5 3 3 0 6 7 6 1 1 5 6 3 0 5 1 3 5 1 5 1 1 5 1 6 5 1 3 1 7 5 1 3 1 3\n",
      " 5 1 7 0 1 6 0 3 5 1 1 1 6 1 1 5 7 1 4 1 6 1 1 5 6 0 7 5 5 3 1 7 5 1 6 5 4\n",
      " 6 0 5 4 1 3 3 5 1 1 6 1 1 3 5 1 1 1 0 6 3 0 3 1 1 1 3 1 1 6 1 1 7 5 5 1 1\n",
      " 1 1 5 4 5 5 3 6 5 3 1 6 6 6 0 1 1 1 5 1 5 0 6 1 2 1 1 1 5 5 1 6 5 1 7 1 1\n",
      " 3 3 1 0 1 1 3 3 6 0 5 5 3 0 5 3 5 1 1 1 1 1 5 6 1 1 5 1 1 1 3 5 7 0 1 5 6\n",
      " 5 3 1 2 1 1 1 3 1 3 5 1 6 3 6 2 1 1 4 5 6 3 1 1 0 2 5 0 7 5 1 6 1 4 6 6 5\n",
      " 6 6 5 7 0 5 5 1 1 5 1 1 0 0 6 4 1 5 7 1 0 1 7 4 1 7 1 1 3 1 5 3 3 5 1 1 1\n",
      " 5 7 1 6 5 5 5 1 1 6 6 6 5 1 0 3 1 0 6 1 1 5 0 2 5 6 4 3 5 0 3 1 1 1 4 6 5\n",
      " 5 5 1 1 3 1 5 4 7 5 3 3 5 5 5 1 5 7 5 3 6 7 1 5 7 6 5 5 6 6 1 6 5 5 1 1 1\n",
      " 5 5 5 1 5 1 0 1 1 6 3 1 1 4 7 1 1 4 7 5 0 1 5 5 6 3 1 0 0 6 3 7 1 3 1 3 1\n",
      " 5 1 7 6 5 6 5 3 5 1 6 5 5 4 5 3 1 3 6 5 1 3 2 7 1 2 3 3 2 5 0 1 7 7 6 6 6\n",
      " 3 5 3 1 1 5 6 6 1 1 6 1 7 3 5 1 5 0 3 5 6 1 3 1 1 1 1 2 1 1 1 6 5 5 1 1 5\n",
      " 4 3 1 3 5 0 0 5 1 6 0 1 3 5 5 6 3 5 3 7 5 5 1 6 7 7 3 0 6 2 3 1 1 1 3 0 0\n",
      " 6 3 1 5 6 5 1 1 5 5 2 0 1 5 5 3 5 5 1 5 5 0 5 1 5 6 2 7 1 5 1 0 0 4 2 0 1\n",
      " 3 5 1 5 3 3 1 5 3 6 5 1 0 4 0 3 6 3 6 7 1 6 1 6 1 6 1 5 0 1 6 5 6 1 2 3 3\n",
      " 7 1 5 1 1 1 5 1 3 1 5]\n",
      "(571, 6)\n",
      "(143, 6)\n",
      "(571,)\n",
      "(143,)\n"
     ]
    }
   ],
   "source": [
    "# Predict Age_group\n",
    "\n",
    "age_feature_list = ['Fare', 'SibSp','Pclass', 'Cabin_cat', 'Parch', 'Title']\n",
    "process_feature_list = ['Fare', 'SibSp','Pclass', 'Cabin_cat','Parch', 'Title', 'Age_group', 'Age']\n",
    "assign_into_object(train, process_feature_list)\n",
    "\n",
    "knownAge = train.loc[(train.Age.notnull())]\n",
    "unknownAge = train.loc[(train.Age.isnull())]\n",
    "print len(knownAge)\n",
    "\n",
    "age_label = knownAge['Age_group'].values\n",
    "age_features = knownAge[age_feature_list].values\n",
    "\n",
    "print age_label\n",
    "\n",
    "# Split to train and test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_features, test_features, train_labels,test_labels = train_test_split(\n",
    "age_features, age_label, test_size = 0.2, random_state = 0 )\n",
    "\n",
    "print train_features.shape\n",
    "print test_features.shape\n",
    "print train_labels.shape\n",
    "print test_labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([0, 1, 2, 3, 4, 5, 6, 7], dtype=object),)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-209-22cebcefe99b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ruyi/anaconda2/lib/python2.7/site-packages/sklearn/naive_bayes.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[0;32m--> 184\u001b[0;31m                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ruyi/anaconda2/lib/python2.7/site-packages/sklearn/naive_bayes.pyc\u001b[0m in \u001b[0;36m_partial_fit\u001b[0;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0m_check_partial_fit_first_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0;31m# This is the first call to partial_fit:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;31m# initialize various cumulative counters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ruyi/anaconda2/lib/python2.7/site-packages/sklearn/utils/multiclass.pyc\u001b[0m in \u001b[0;36m_check_partial_fit_first_call\u001b[0;34m(clf, classes)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0;31m# This is the first call to partial_fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ruyi/anaconda2/lib/python2.7/site-packages/sklearn/utils/multiclass.pyc\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0m_unique_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FN_UNIQUE_LABELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_unique_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mys_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: (array([0, 1, 2, 3, 4, 5, 6, 7], dtype=object),)"
     ]
    }
   ],
   "source": [
    "# Age_Group prediction - SVR\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(train_features, train_labels)\n",
    "pred = clf.predict(test_features)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(pred, test_features)\n",
    "print 'Accuracy score:', accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction (143,)\n",
      "test_labels: (143,)\n",
      "0.149948355776\n"
     ]
    }
   ],
   "source": [
    "# Age_group prediction - Linear_model.Lasso\n",
    "\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.Lasso(alpha = 0.1)\n",
    "reg.fit(train_features, train_labels)\n",
    "pred = reg.predict(test_features)\n",
    "print 'prediction', pred.shape\n",
    "print 'test_labels:', test_labels.shape\n",
    "#reg.score(test_features, test_labels)\n",
    "\n",
    "from sklearn.metrics import explained_variance_score\n",
    "print explained_variance_score(test_labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train = missing_age_predictor(train)\n",
    "print train.isnull().sum()\n",
    "train.shape\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Cabin  Pclass\n",
      "1   C85       1\n",
      "3  C123       1\n",
      "6   E46       1\n",
      "(204, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruyi/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Exploring Cabin data\n",
    "\n",
    "cabin_df = train[['Cabin', 'Pclass']]\n",
    "cabin_df.dropna(inplace = True)\n",
    "print cabin_df.head(3)\n",
    "print cabin_df.shape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruyi/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 6)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-beb654a3df14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeaturing_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-180-a851c4835449>\u001b[0m in \u001b[0;36mfeaturing_process\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# predict missing Age by ['Fare', 'SibSp','Pclass', 'Cabin_cat','Parch', 'Title']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mmissing_age_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# add Age_group by Age\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-140-36b048e7593b>\u001b[0m in \u001b[0;36mmissing_age_predictor\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLasso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mpredict_age\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munknown_age_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Age'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_age\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ruyi/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ruyi/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/coordinate_descent.pyc\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    779\u001b[0m                                    dense_output=True) + self.intercept_\n\u001b[1;32m    780\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mElasticNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ruyi/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coef_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[1;32m    253\u001b[0m                                dense_output=True) + self.intercept_\n",
      "\u001b[0;32m/Users/ruyi/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    414\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                              % (n_samples, shape_repr, ensure_min_samples,\n\u001b[0;32m--> 416\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 6)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "featuring_process(train)\n",
    "print train.shape\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', 'D', 'E', 'F', 'G', 'T'}"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train['Cabin_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['A', '1', '4', 'F'])\n",
      "4\n",
      "[0, 1, 2]\n",
      "[('A', 0), ('1', 1), ('4', 2), ('F', 3)]\n",
      "{'A': 0, '1': 1, '4': 2, 'F': 3}\n",
      "['PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch'\n",
      " 'Ticket' 'Fare' 'Cabin' 'Embarked' 'Family_size' 'Cabin_cat']\n",
      "zip: ['male', 'female'] {'male': 0, 'female': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruyi/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family_size</th>\n",
       "      <th>Cabin_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris   0  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...   1  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina   1  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)   1  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry   0  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked  Family_size Cabin_cat  \n",
       "0         A/5 21171   7.2500   NaN        S            2         F  \n",
       "1          PC 17599  71.2833   C85        C            2         C  \n",
       "2  STON/O2. 3101282   7.9250   NaN        S            1         F  \n",
       "3            113803  53.1000  C123        S            2         C  \n",
       "4            373450   8.0500   NaN        S            1         F  "
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n",
    "y2 = [\"A\",\"1\",\"4\",\"F\",\"A\",\"1\",\"4\",\"F\"]\n",
    "S = set(y2)\n",
    "print S\n",
    "print len(S)\n",
    "print range(3)\n",
    "print zip(S, range(len(S)))\n",
    "D = dict( zip(S, range(len(S))) )\n",
    "print D\n",
    "\n",
    "print train.columns.values\n",
    "\n",
    "\n",
    "\n",
    "unique_values, result_dict = transfor_to_numeric(train, \"Sex\")\n",
    "print 'zip:', unique_values, result_dict\n",
    "\n",
    "\n",
    "    \n",
    "assign_numeric_values (train, \"Sex\", unique_values, result_dict)\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruyi/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "Age_group        0\n",
       "Title            0\n",
       "Family_size      0\n",
       "Cabin_cat        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "feature_list = ['Sex', 'Family_size', 'Cabin_cat', 'Title', 'Age_group']\n",
    "#train['Age'].fillna(random.gauss(mu, sigma), inplace = True)\n",
    "train['Age_group'] = train['Age'].apply(age_grouping)\n",
    "assign_into_object(train, feature_list)\n",
    "train.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "# exclude datapoint without age number\n",
    "\n",
    "#train[\"Age\"][train[\"Age\"].isnull()] = 9999\n",
    "#print set(train[\"Age\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare for estimator testing\n",
    "# Whole dataset\n",
    "labels = train['Survived'].values\n",
    "features = train[feature_list].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: (757, 5)\n",
      "Train labels: (757,)\n",
      "Test features: (134, 5)\n",
      "Test labels: (134,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split to train and test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features, test_features, train_labels,test_labels = train_test_split(\n",
    "features, labels, test_size = 0.15, random_state = 0 )\n",
    "\n",
    "\n",
    "print \"Train features:\", train_features.shape\n",
    "print \"Train labels:\", train_labels.shape\n",
    "print \"Test features:\", test_features.shape\n",
    "print \"Test labels:\",test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 1: 0.822\n",
      "Score for fold 2: 0.831\n",
      "Score for fold 3: 0.753\n",
      "Score for fold 4: 0.831\n",
      "Score for fold 5: 0.809\n",
      "Score for fold 6: 0.809\n",
      "Score for fold 7: 0.787\n",
      "Score for fold 8: 0.787\n",
      "Score for fold 9: 0.876\n",
      "Score for fold 10: 0.820\n"
     ]
    }
   ],
   "source": [
    "# Use KFold to split train/test data\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Load the data:\n",
    "#iris = load_iris()\n",
    "#X, y = iris.data, iris.target\n",
    " \n",
    "# Split in 5 folds:\n",
    "#n = len(X)\n",
    "#kf = KFold(n_splits=5)\n",
    "#fold = 0\n",
    "#for train_idx, test_idx in kf.split(X):\n",
    "#    fold += 1\n",
    "#    X_train, X_test = X[train_idx], X[test_idx]\n",
    "#    y_train, y_test = y[train_idx], y[test_idx]\n",
    "#    clf = LogisticRegression().fit(X_train, y_train)\n",
    "#    score = clf.score(X_test, y_test)\n",
    "#    print(\"Score for fold %d: %.3f\" % (fold, score))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split in 5 folds\n",
    "n = len(train)\n",
    "kf = KFold(n_splits=10)\n",
    "fold = 0\n",
    "for train_idx, test_idx in kf.split(features):\n",
    "    fold += 1\n",
    "    X_train, X_test = features[train_idx], features[test_idx]\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "    clf = LogisticRegression().fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(\"Score for fold %d: %.3f\" % (fold, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf name: LinearSVC\n",
      "Cross-validated scores: 0.7306238379\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC\n",
    "import time\n",
    "from sklearn import svm\n",
    "\n",
    "print 'clf name: LinearSVC'\n",
    "clf = svm.LinearSVC()\n",
    "'''\n",
    "t0 = time.time()\n",
    "clf.fit(train_features, train_labels)\n",
    "print \"training time:\", round(time.time()-t0, 3), \"s\"\n",
    "\n",
    "t0 = time.time()\n",
    "pred = clf.predict(test_features)\n",
    "print \"predicting time:\", round(time.time()-t0, 3), \"s\"\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(pred, test_labels)\n",
    "print 'Accuracy score:', accuracy\n",
    "'''\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "scores = cross_val_score(clf, features, labels, cv=5)\n",
    "print 'Cross-validated scores:', scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: 0.802464547854\n"
     ]
    }
   ],
   "source": [
    "# naive_bayes_clf\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "'''   \n",
    "print 'clf name: Naive Bayes'\n",
    "t0 = time.time()\n",
    "clf.fit(train_features, train_labels)\n",
    "print \"training time:\", round(time.time()-t0, 3), \"s\"\n",
    "\n",
    "t0 = time.time()\n",
    "pred = clf.predict(test_features)\n",
    "print \"predicting time:\", round(time.time()-t0, 3), \"s\"\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(pred, test_labels)\n",
    "print 'accuracy score:', accuracy\n",
    "\n",
    "print 'GaussianNB priors:', clf.class_prior_\n",
    "'''\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "scores = cross_val_score(clf, features, labels, cv=5)\n",
    "print 'Cross-validated scores:', scores.mean()\n",
    "\n",
    "clf.fit(features, labels)\n",
    "\n",
    "previous_score = 0.791285015499\n",
    "seconde_score = 0.801347229418  #Age is randomly assigned numbers. feature_list = ['Sex', 'Age', 'Family_size', 'Cabin_cat', 'Title']\n",
    "third_score =  0.805879557569 # Age_group is based on randomly assigned ages. feature_list = ['Sex', 'Age', 'Family_size', 'Cabin_cat', 'Title', 'Age_group']\n",
    "fourth_score = 0.801353506488 # feature_list = ['Sex',  'Family_size', 'Cabin_cat', 'Title', 'Age_group']\n",
    "fifth_score = 0.802464547854 # Age predicted by another estimator. feature_list = ['Sex',  'Family_size', 'Cabin_cat', 'Title', 'Age']\n",
    "sixth_score = 0.802464547854 # Age predicted by another estimator. feature_list = ['Sex',  'Family_size', 'Cabin_cat', 'Title', 'Age_group']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: 0.760947511284\n"
     ]
    }
   ],
   "source": [
    "### KNeighbors clf\n",
    "def Kneightbors_clf(features_train,labels_train, \\\n",
    "                    features_test,labels_test):\n",
    "\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    clf = KNeighborsClassifier(n_neighbors = 2)\n",
    "    \n",
    "    print 'clf name: KNeighbors'\n",
    "    t0 = time.time()\n",
    "    clf.fit(features_train, labels_train)\n",
    "    print \"training time:\", round(time.time()-t0, 3), \"s\"\n",
    "\n",
    "    t0 = time.time()\n",
    "    pred = clf.predict(features_test)\n",
    "    print \"predicting time:\", round(time.time()-t0, 3), \"s\"\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score\n",
    "    accuracy = accuracy_score(pred, labels_test)\n",
    "    print 'accuracy score:', accuracy\n",
    "\n",
    "#Kneightbors_clf(train_features, train_labels, \\\n",
    "#              test_features, test_labels)    \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors = 2)\n",
    "\n",
    "scores = cross_val_score(clf, features, labels, cv=5)\n",
    "print 'Cross-validated scores:', scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: 0.789031405564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### SVC clf\n",
    "\n",
    "def SVC_clf(features_train,labels_train, \\\n",
    "                    features_test,labels_test):\n",
    "\n",
    "    from sklearn import svm\n",
    "    clf = svm.SVC(C=1.0, kernel='rbf')\n",
    "    \n",
    "    print 'clf name: SVC'\n",
    "    t0 = time.time()\n",
    "    clf.fit(features_train, labels_train)\n",
    "    print \"training time:\", round(time.time()-t0, 3), \"s\"\n",
    "\n",
    "    t0 = time.time()\n",
    "    pred = clf.predict(features_test)\n",
    "    print \"predicting time:\", round(time.time()-t0, 3), \"s\"\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    accuracy = accuracy_score(pred, labels_test)\n",
    "    print 'accuracy score:', accuracy\n",
    "\n",
    "#SVC_clf(train_features, train_labels, \\\n",
    "#              test_features, test_labels)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(C=1.0, kernel='rbf')\n",
    "\n",
    "scores = cross_val_score(clf, features, labels, cv=5)\n",
    "print 'Cross-validated scores:', scores.mean()\n",
    "\n",
    "clf.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator found by grid search:\n",
      "Pipeline(steps=[('Scale_Features', MinMaxScaler(copy=True, feature_range=(0, 1))), ('SKB', SelectKBest(k=1, score_func=<function f_classif at 0x1159b26e0>)), ('Classifier', SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best Params found by grid search:\n",
      "{'Classifier__kernel': 'linear', 'Classifier__C': 1, 'SKB__k': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.grid_search import GridSearchCV #sklearn version 0.15\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "skb = SelectKBest()\n",
    "clf = svm.SVC()\n",
    "pipe = Pipeline([('Scale_Features',scaler),('SKB', skb),('Classifier',clf)])\n",
    "\n",
    "#print sorted(pipe.get_params().keys())\n",
    "\n",
    "params = {'SKB__k':range(1,len(feature_list)),'Classifier__kernel':['linear', 'rbf'], 'Classifier__C':[1, 10, 20]}\n",
    "my_clf = GridSearchCV(pipe, param_grid=params, scoring='f1_weighted')\n",
    "my_clf.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "pred = my_clf.predict(test_features)\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print my_clf.best_estimator_\n",
    "print('Best Params found by grid search:')\n",
    "print my_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tune parameters of Naives Bayes with GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, \\\n",
    "                            recall_score, f1_score\n",
    "\n",
    "skb = SelectKBest()\n",
    "clf = GaussianNB()\n",
    "pipe = Pipeline([('SKB', skb),('Classifier',clf)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Family_size' 'Cabin_cat' 'Title' 'Age_group'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-201-7d6a3943eef1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ruyi/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2051\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2053\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2054\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ruyi/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2095\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2096\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2097\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2098\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ruyi/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1228\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1230\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s not in index'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Family_size' 'Cabin_cat' 'Title' 'Age_group'] not in index\""
     ]
    }
   ],
   "source": [
    "# Test dataset\n",
    "test = pd.read_csv('test.csv')\n",
    "test.isnull().sum\n",
    "#featuring_process(test)\n",
    "\n",
    "#assign_into_object(test, feature_list)\n",
    "\n",
    "print test.isnull().sum()\n",
    "\n",
    "\n",
    "test_features = test[feature_list].values\n",
    "\n",
    "pred = clf.predict(test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Survived\n",
      "892          0\n",
      "893          1\n",
      "894          0\n",
      "895          0\n",
      "896          1\n",
      "897          0\n",
      "898          1\n",
      "899          0\n",
      "900          1\n",
      "901          0\n",
      "902          0\n",
      "903          0\n",
      "904          1\n",
      "905          0\n",
      "906          1\n",
      "907          1\n",
      "908          0\n",
      "909          0\n",
      "910          1\n",
      "911          1\n",
      "912          0\n",
      "913          0\n",
      "914          1\n",
      "915          0\n",
      "916          1\n",
      "917          0\n",
      "918          1\n",
      "919          0\n",
      "920          1\n",
      "921          0\n",
      "...        ...\n",
      "1280         0\n",
      "1281         0\n",
      "1282         0\n",
      "1283         1\n",
      "1284         0\n",
      "1285         0\n",
      "1286         0\n",
      "1287         1\n",
      "1288         0\n",
      "1289         1\n",
      "1290         0\n",
      "1291         0\n",
      "1292         1\n",
      "1293         0\n",
      "1294         1\n",
      "1295         0\n",
      "1296         0\n",
      "1297         0\n",
      "1298         0\n",
      "1299         0\n",
      "1300         1\n",
      "1301         1\n",
      "1302         1\n",
      "1303         1\n",
      "1304         1\n",
      "1305         0\n",
      "1306         1\n",
      "1307         0\n",
      "1308         0\n",
      "1309         0\n",
      "\n",
      "[418 rows x 1 columns]\n",
      "(418, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a data frame with two columns: PassengerId & Survived. Survived contains your predictions\n",
    "PassengerId =np.array(test[\"PassengerId\"]).astype(int)\n",
    "my_solution = pd.DataFrame(pred, PassengerId, columns = [\"Survived\"])\n",
    "print(my_solution)\n",
    "\n",
    "# Check that your data frame has 418 entries\n",
    "print(my_solution.shape)\n",
    "\n",
    "# Write your solution to a csv file with the name my_solution.csv\n",
    "my_solution.to_csv(\"my_solution_8.csv\", index_label = [\"PassengerId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s2 = pd.read_csv(\"my_solution_2.csv\")\n",
    "s3 = pd.read_csv(\"my_solution_3.csv\")\n",
    "s4 = pd.read_csv(\"my_solution_4.csv\")\n",
    "s5 = pd.read_csv(\"my_solution_5.csv\")\n",
    "s6 = pd.read_csv(\"my_solution_6.csv\")\n",
    "s7 = pd.read_csv(\"my_solution_7.csv\")\n",
    "s8 = pd.read_csv(\"my_solution_8.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s7.equals(s8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n",
      "152\n",
      "184\n",
      "139\n",
      "152\n",
      "149\n",
      "151\n"
     ]
    }
   ],
   "source": [
    "def count_survival(df):\n",
    "    print df['Survived'].sum()\n",
    "\n",
    "count_survival(s2)\n",
    "count_survival(s3)    \n",
    "count_survival(s4)\n",
    "count_survival(s5)\n",
    "count_survival(s6)\n",
    "count_survival(s7)\n",
    "count_survival(s8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
